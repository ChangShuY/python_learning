{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Stuidio 七天课程之前置课程  \n",
    "MINST  \n",
    "CSY 2020-2-4  \n",
    "程序来源：https://aistudio.baidu.com/aistudio/projectdetail/256596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Step1:准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import numpy as np\n",
    "# import paddle as paddle\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#train_reader = paddle.batch(paddle.reader.shuffle(paddle.dataset.mnist.train(),buf_size=512),batch_size=128)\n",
    "#test_reader = paddle.batch(paddle.dataset.mnist.test(),batch_size=128)\n",
    "\n",
    "train_reader = fluid.io.batch(\n",
    "                                fluid.io.shuffle(paddle.dataset.mnist.train(),\n",
    "                                                      buf_size=512),\n",
    "                                batch_size=128)\n",
    "test_reader = fluid.io.batch(paddle.dataset.mnist.test(),batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印一下，观察一下mnist数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -0.9764706 , -0.85882354, -0.85882354,\n",
      "       -0.85882354, -0.01176471,  0.06666672,  0.37254906, -0.79607844,\n",
      "        0.30196083,  1.        ,  0.9372549 , -0.00392157, -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -0.7647059 , -0.7176471 , -0.26274508,  0.20784318,\n",
      "        0.33333337,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9843137 ,  0.7647059 ,  0.34901965,  0.9843137 ,  0.8980392 ,\n",
      "        0.5294118 , -0.4980392 , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -0.6156863 ,  0.8666667 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.96862745, -0.27058822,\n",
      "       -0.35686272, -0.35686272, -0.56078434, -0.69411767, -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -0.85882354,  0.7176471 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5529412 ,  0.427451  ,\n",
      "        0.9372549 ,  0.8901961 , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -0.372549  ,  0.22352946, -0.1607843 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.60784316, -0.9137255 , -1.        , -0.6627451 ,  0.20784318,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -0.8901961 ,\n",
      "       -0.99215686,  0.20784318,  0.9843137 , -0.29411763, -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        ,  0.09019613,\n",
      "        0.9843137 ,  0.4901961 , -0.9843137 , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -0.9137255 ,  0.4901961 ,  0.9843137 ,\n",
      "       -0.45098037, -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -0.7254902 ,  0.8901961 ,  0.7647059 ,  0.254902  ,\n",
      "       -0.15294117, -0.99215686, -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -0.36470586,  0.88235295,  0.9843137 ,  0.9843137 , -0.06666666,\n",
      "       -0.8039216 , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -0.64705884,\n",
      "        0.45882356,  0.9843137 ,  0.9843137 ,  0.17647064, -0.7882353 ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -0.8745098 , -0.27058822,\n",
      "        0.9764706 ,  0.9843137 ,  0.4666667 , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        ,  0.9529412 ,  0.9843137 ,\n",
      "        0.9529412 , -0.4980392 , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -0.6392157 ,  0.0196079 ,\n",
      "        0.43529415,  0.9843137 ,  0.9843137 ,  0.62352943, -0.9843137 ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -0.69411767,\n",
      "        0.16078436,  0.79607844,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9607843 ,  0.427451  , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -0.8117647 , -0.10588235,  0.73333335,  0.9843137 ,  0.9843137 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.5764706 , -0.38823527, -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -0.81960785, -0.4823529 ,  0.67058825,  0.9843137 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5529412 , -0.36470586,\n",
      "       -0.9843137 , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -0.85882354,  0.3411765 ,  0.7176471 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5294118 ,\n",
      "       -0.372549  , -0.92941177, -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -0.5686275 ,  0.34901965,\n",
      "        0.77254903,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9137255 ,  0.04313731, -0.9137255 , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        ,  0.06666672,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.6627451 ,  0.05882359,  0.03529418, -0.8745098 , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        ], dtype=float32), 5)]\n"
     ]
    }
   ],
   "source": [
    "temp_reader = fluid.io.batch(paddle.dataset.mnist.train(),\n",
    "                           batch_size=1)\n",
    "temp_data=next(temp_reader())\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2:配置网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入层-->>隐层-->>隐层-->>输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义多层感知器\n",
    "def multilayer_perceptron(input):\n",
    "    # 第一个全连接层，激活函数为ReLU\n",
    "    hidden1 = fluid.layers.fc(input=input, size=100, act='relu')\n",
    "    # 第二个全连接层，激活函数为ReLU\n",
    "    hidden2 = fluid.layers.fc(input=hidden1, size=100, act='relu')\n",
    "    # 以softmax为激活函数的全连接输出层，大小为10\n",
    "    prediction = fluid.layers.fc(input=hidden2, size=10, act='softmax')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入输出层\n",
    "image = fluid.layers.data(name='image', shape=[1, 28, 28], dtype='float32')  #单通道，28*28像素值\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')            #图片标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用定义好的网络来获取分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取分类器\n",
    "model = multilayer_perceptron(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着是定义损失函数，这次使用的是交叉熵损失函数，该函数在分类任务上比较常用。  \n",
    "定义了一个损失函数之后，还有对它求平均值，因为定义的是一个Batch的损失值。  \n",
    "同时我们还可以定义一个准确率函数，这个可以在我们训练的时候输出分类的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取损失函数和准确率函数\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)  #使用交叉熵损失函数,描述真实样本标签和预测概率之间的差值\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "acc = fluid.layers.accuracy(input=model, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义优化方法，这次我们使用的是Adam优化方法，同时指定学习率为0.001。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化方法\n",
    "optimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.001)   #使用Adam算法进行优化\n",
    "opts = optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3:模型训练 & STEP4:模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个使用CPU的解析器\n",
    "place = fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "# 进行参数初始化\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入数据维度\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[image, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们这次训练5个Pass。在上面我们已经定义了一个求准确率的函数，所以我们在训练的时候让它输出当前的准确率，计算准确率的原理很简单，就是把训练是预测的结果和真实的值比较，求出准确率。每一个Pass训练结束之后，再进行一次测试，使用测试集进行测试，并求出当前的Cost和准确率的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:2.53542, Accuracy:0.10938\n",
      "Pass:0, Batch:100, Cost:0.50689, Accuracy:0.83594\n",
      "Pass:0, Batch:200, Cost:0.28470, Accuracy:0.90625\n",
      "Pass:0, Batch:300, Cost:0.22555, Accuracy:0.91406\n",
      "Pass:0, Batch:400, Cost:0.22402, Accuracy:0.92188\n",
      "Test:0, Cost:0.21729, Accuracy:0.93295\n",
      "save models to ./inference.model\n",
      "Pass:1, Batch:0, Cost:0.24503, Accuracy:0.92969\n",
      "Pass:1, Batch:100, Cost:0.12446, Accuracy:0.95312\n",
      "Pass:1, Batch:200, Cost:0.14748, Accuracy:0.96875\n",
      "Pass:1, Batch:300, Cost:0.19443, Accuracy:0.92188\n",
      "Pass:1, Batch:400, Cost:0.13431, Accuracy:0.96875\n",
      "Test:1, Cost:0.14296, Accuracy:0.95520\n",
      "save models to ./inference.model\n",
      "Pass:2, Batch:0, Cost:0.15846, Accuracy:0.96094\n",
      "Pass:2, Batch:100, Cost:0.05457, Accuracy:0.98438\n",
      "Pass:2, Batch:200, Cost:0.06094, Accuracy:0.99219\n",
      "Pass:2, Batch:300, Cost:0.15036, Accuracy:0.96094\n",
      "Pass:2, Batch:400, Cost:0.18563, Accuracy:0.94531\n",
      "Test:2, Cost:0.12023, Accuracy:0.96282\n",
      "save models to ./inference.model\n",
      "Pass:3, Batch:0, Cost:0.15303, Accuracy:0.95312\n",
      "Pass:3, Batch:100, Cost:0.06195, Accuracy:0.97656\n",
      "Pass:3, Batch:200, Cost:0.06967, Accuracy:0.96875\n",
      "Pass:3, Batch:300, Cost:0.07260, Accuracy:0.97656\n",
      "Pass:3, Batch:400, Cost:0.15880, Accuracy:0.93750\n",
      "Test:3, Cost:0.10402, Accuracy:0.96756\n",
      "save models to ./inference.model\n",
      "Pass:4, Batch:0, Cost:0.09496, Accuracy:0.96875\n",
      "Pass:4, Batch:100, Cost:0.06339, Accuracy:0.96875\n",
      "Pass:4, Batch:200, Cost:0.13163, Accuracy:0.95312\n",
      "Pass:4, Batch:300, Cost:0.05902, Accuracy:0.97656\n",
      "Pass:4, Batch:400, Cost:0.07706, Accuracy:0.96875\n",
      "Test:4, Cost:0.09444, Accuracy:0.96954\n",
      "save models to ./inference.model\n"
     ]
    }
   ],
   "source": [
    "# 开始训练和测试\n",
    "for pass_id in range(5):\n",
    "    # 进行训练\n",
    "    for batch_id, data in enumerate(train_reader()):                        #遍历train_reader: 下标和元素\n",
    "        train_cost, train_acc = exe.run(program=fluid.default_main_program(),#运行主程序\n",
    "                                        feed=feeder.feed(data),             #给模型喂入数据\n",
    "                                        fetch_list=[avg_cost, acc])         #fetch 误差、准确率\n",
    "        # 每100个batch打印一次信息  误差、准确率\n",
    "        if batch_id % 100 == 0:\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))\n",
    "\n",
    "    # 进行测试\n",
    "    test_accs = []\n",
    "    test_costs = []\n",
    "    #每训练一轮 进行一次测试\n",
    "    for batch_id, data in enumerate(test_reader()):                         #遍历test_reader\n",
    "        test_cost, test_acc = exe.run(program=fluid.default_main_program(), #执行训练程序\n",
    "                                      feed=feeder.feed(data),               #喂入数据\n",
    "                                      fetch_list=[avg_cost, acc])           #fetch 误差、准确率\n",
    "        test_accs.append(test_acc[0])                                       #每个batch的准确率\n",
    "        test_costs.append(test_cost[0])                                     #每个batch的误差\n",
    "    # 求测试结果的平均值\n",
    "    test_cost = (sum(test_costs) / len(test_costs))                         #每轮的平均误差\n",
    "    test_acc = (sum(test_accs) / len(test_accs))                            #每轮的平均准确率\n",
    "    print('Test:%d, Cost:%0.5f, Accuracy:%0.5f' % (pass_id, test_cost, test_acc))\n",
    "    \n",
    "    #保存模型\n",
    "    model_save_dir = \"./inference.model\"\n",
    "    # 如果保存路径不存在就创建\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "    print ('save models to %s' % (model_save_dir))\n",
    "    fluid.io.save_inference_model(model_save_dir,  #保存推理model的路径\n",
    "                                  ['image'],      #推理（inference）需要 feed 的数据\n",
    "                                  [model],        #保存推理（inference）结果的 Variables\n",
    "                                  exe)            #executor 保存 inference model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5:模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在预测之前，要对图像进行预处理，处理方式要跟训练的时候一样。首先进行灰度化，然后压缩图像大小为28*28，接着将图像转换成一维向量，最后再对一维向量进行归一化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对图片进行预处理\n",
    "def load_image(file):\n",
    "    im = Image.open(file).convert('L')                        #将RGB转化为灰度图像，L代表灰度图像，灰度图像的像素值在0~255之间\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)                 #resize image with high-quality 图像大小为28*28\n",
    "    im = np.array(im).reshape(1, 1, 28, 28).astype(np.float32)#返回新形状的数组,把它变成一个 numpy 数组以匹配数据馈送格式。\n",
    "   # print(im)\n",
    "    im = im / 255.0 * 2.0 - 1.0                               #归一化到【-1~1】之间\n",
    "    print(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先看看用于预测的图像是什么样子？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open('../../CheckCode/data/6.jpg')\n",
    "plt.imshow(img)   #根据数组绘制图像\n",
    "plt.show()        #显示图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_exe = fluid.Executor(place)\n",
    "inference_scope = fluid.core.Scope()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后把图像转换成一维向量并进行预测，数据从feed中的image传入。fetch_list的值是网络模型的最后一层分类器，所以输出的结果是10个标签的概率值，这些概率值的总和为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.8509804  -0.85882354 -0.8666667  -0.8666667  -0.8509804\n",
      "    -0.84313726 -0.8352941  -0.84313726 -0.8509804  -0.8666667\n",
      "    -0.8745098  -0.88235295 -0.85882354 -0.8117647  -0.8117647\n",
      "    -0.8509804  -0.8666667  -0.84313726 -0.827451   -0.8352941\n",
      "    -0.8509804  -0.8745098  -0.8666667  -0.84313726 -0.81960785\n",
      "    -0.8117647  -0.81960785 -0.827451  ]\n",
      "   [ 0.77254903  0.79607844  0.8352941   0.8509804   0.8352941\n",
      "     0.8117647   0.79607844  0.81960785  0.8745098   0.9529412\n",
      "     0.99215686  0.96862745  0.8745098   0.75686276  0.7411765\n",
      "     0.84313726  0.8901961   0.88235295  0.88235295  0.88235295\n",
      "     0.8745098   0.84313726  0.8117647   0.7882353   0.77254903\n",
      "     0.79607844  0.827451    0.84313726]\n",
      "   [ 0.77254903  0.75686276  0.73333335  0.7254902   0.7411765\n",
      "     0.77254903  0.79607844  0.7882353   0.75686276  0.7176471\n",
      "     0.69411767  0.70980394  0.77254903  0.8352941   0.81960785\n",
      "     0.7490196   0.70980394  0.7176471   0.7254902   0.7411765\n",
      "     0.7647059   0.7882353   0.7882353   0.77254903  0.75686276\n",
      "     0.7411765   0.7411765   0.7411765 ]\n",
      "   [ 0.81960785  0.8117647   0.8039216   0.8039216   0.81960785\n",
      "     0.84313726  0.85882354  0.85882354  0.81960785  0.7647059\n",
      "     0.73333335  0.73333335  0.7490196   0.7882353   0.8352941\n",
      "     0.88235295  0.88235295  0.8509804   0.8117647   0.78039217\n",
      "     0.75686276  0.75686276  0.77254903  0.8117647   0.84313726\n",
      "     0.84313726  0.81960785  0.8117647 ]\n",
      "   [ 0.75686276  0.78039217  0.827451    0.8509804   0.827451\n",
      "     0.78039217  0.7490196   0.7647059   0.827451    0.8980392\n",
      "     0.92941177  0.90588236  0.7882353   0.67058825  0.6784314\n",
      "     0.81960785  0.90588236  0.8980392   0.88235295  0.8509804\n",
      "     0.79607844  0.7490196   0.7254902   0.7411765   0.78039217\n",
      "     0.8117647   0.827451    0.827451  ]\n",
      "   [ 0.8745098   0.8509804   0.79607844  0.7490196   0.7176471\n",
      "     0.7176471   0.7254902   0.70980394  0.6862745   0.6784314\n",
      "     0.69411767  0.73333335  0.8352941   0.92941177  0.8117647\n",
      "     0.5686275   0.47450984  0.58431375  0.67058825  0.73333335\n",
      "     0.77254903  0.79607844  0.827451    0.827451    0.8039216\n",
      "     0.77254903  0.7647059   0.7647059 ]\n",
      "   [ 0.79607844  0.77254903  0.75686276  0.81960785  0.8901961\n",
      "     0.92941177  0.92941177  0.9372549   0.92941177  0.90588236\n",
      "     0.8980392   0.92156863  0.9529412   0.9607843   0.9529412\n",
      "     0.8901961   0.7490196   0.6156863   0.5137255   0.5529412\n",
      "     0.7176471   0.88235295  0.92941177  0.8745098   0.8039216\n",
      "     0.7490196   0.7411765   0.7490196 ]\n",
      "   [ 0.69411767  0.75686276  0.7647059   0.4901961   0.13725495\n",
      "     0.03529418  0.09019613  0.05882359  0.0196079   0.05882359\n",
      "     0.09019613  0.05098045 -0.03529412 -0.09803921 -0.03529412\n",
      "     0.09803927  0.13725495  0.05098045 -0.02745098 -0.09803921\n",
      "    -0.21568626 -0.10588235  0.34901965  0.7882353   0.90588236\n",
      "     0.8117647   0.7254902   0.67058825]\n",
      "   [ 0.7882353   0.8745098   0.8039216   0.20784318 -0.5372549\n",
      "    -0.84313726 -0.7647059  -0.7176471  -0.67058825 -0.58431375\n",
      "    -0.5921569  -0.7019608  -0.7176471  -0.6156863  -0.62352943\n",
      "    -0.77254903 -0.827451   -0.75686276 -0.67058825 -0.6862745\n",
      "    -0.9529412  -0.81960785  0.10588241  0.94509804  1.\n",
      "     0.7882353   0.7411765   0.7254902 ]\n",
      "   [ 0.64705884  0.9137255   1.          0.35686278 -0.6627451\n",
      "    -0.84313726 -0.5686275  -0.69411767 -0.8980392  -0.8039216\n",
      "    -0.6627451  -0.654902   -0.7019608  -0.7254902  -0.654902\n",
      "    -0.5372549  -0.5294118  -0.5921569  -0.6862745  -0.54509807\n",
      "    -0.01176471  0.41960788  0.33333337  0.2313726   0.6156863\n",
      "     0.8980392   0.8117647   0.69411767]\n",
      "   [ 0.8901961   0.5372549  -0.09019607 -0.5921569  -0.52156866\n",
      "    -0.12156862  0.3411765   0.5058824   0.49803925  0.5529412\n",
      "     0.5372549   0.43529415  0.3411765   0.28627455  0.41176474\n",
      "     0.48235297  0.13725495 -0.45098037 -0.92941177 -0.7882353\n",
      "     0.15294123  1.          0.8745098   0.45098042  0.09803927\n",
      "     0.22352946  0.6392157   0.92941177]\n",
      "   [ 1.          0.36470592 -0.52156866 -0.4980392   0.36470592\n",
      "     0.70980394  0.69411767  0.827451    0.9372549   0.90588236\n",
      "     0.8039216   0.75686276  0.79607844  0.8980392   1.\n",
      "     1.          0.5058824  -0.45098037 -0.94509804 -0.7176471\n",
      "    -0.02745098  0.67058825  0.9137255   0.8980392   0.8352941\n",
      "     0.5294118   0.17647064 -0.01176471]\n",
      "   [ 0.7019608   0.6784314   0.6627451   0.6784314   0.7490196\n",
      "     0.8509804   0.90588236  0.827451    0.7254902   0.7019608\n",
      "     0.7411765   0.7411765   0.8039216   0.7882353   0.38823533\n",
      "    -0.27058822 -0.7882353  -0.77254903 -0.12941176  0.67058825\n",
      "     0.90588236  0.8901961   0.7254902   0.6784314   0.84313726\n",
      "     0.9372549   0.8352941   0.7490196 ]\n",
      "   [ 0.78039217  0.75686276  0.75686276  0.81960785  0.8901961\n",
      "     0.85882354  0.79607844  0.8352941   0.8666667   0.7647059\n",
      "     0.7019608   0.7176471   0.8901961   0.96862745  0.49803925\n",
      "    -0.3333333  -0.8980392  -0.75686276  0.01176476  0.81960785\n",
      "     1.          0.75686276  0.6392157   0.6627451   0.7490196\n",
      "     0.79607844  0.75686276  0.7176471 ]\n",
      "   [ 0.69411767  0.79607844  0.92156863  0.88235295  0.7254902\n",
      "     0.6862745   0.7176471   0.70980394  0.7411765   0.81960785\n",
      "     0.92941177  0.9372549   0.48235297 -0.27843136 -0.8509804\n",
      "    -0.81960785 -0.1372549   0.69411767  0.9843137   0.8117647\n",
      "     0.67058825  0.69411767  0.827451    0.92941177  0.8666667\n",
      "     0.77254903  0.7647059   0.77254903]\n",
      "   [ 0.73333335  0.7882353   0.84313726  0.78039217  0.6627451\n",
      "     0.6862745   0.7882353   0.8117647   0.79607844  0.7490196\n",
      "     0.8745098   1.          0.6862745  -0.19999999 -0.88235295\n",
      "    -0.8666667  -0.17647058  0.6627451   0.90588236  0.70980394\n",
      "     0.73333335  0.85882354  0.827451    0.78039217  0.81960785\n",
      "     0.8509804   0.827451    0.8117647 ]\n",
      "   [ 0.88235295  0.8352941   0.7882353   0.8117647   0.88235295\n",
      "     0.8980392   0.8352941   0.7411765   0.7019608   0.7176471\n",
      "     0.77254903  0.7176471   0.2941177  -0.36470586 -0.77254903\n",
      "    -0.6313726  -0.02745098  0.654902    0.94509804  0.8745098\n",
      "     0.827451    0.8117647   0.7490196   0.73333335  0.75686276\n",
      "     0.8039216   0.81960785  0.827451  ]\n",
      "   [ 0.7490196   0.7411765   0.7490196   0.7647059   0.77254903\n",
      "     0.77254903  0.77254903  0.75686276  0.8117647   0.9529412\n",
      "     0.6392157  -0.17647058 -0.8509804  -0.85882354 -0.19999999\n",
      "     0.70980394  1.          0.96862745  0.79607844  0.73333335\n",
      "     0.67058825  0.69411767  0.8117647   0.8980392   0.8901961\n",
      "     0.85882354  0.8509804   0.8509804 ]\n",
      "   [ 0.73333335  0.8039216   0.8901961   0.8509804   0.7490196\n",
      "     0.79607844  0.8666667   0.7490196   0.7490196   1.\n",
      "     0.81960785  0.00392163 -0.81960785 -1.         -0.41960782\n",
      "     0.5764706   0.92156863  0.7176471   0.654902    0.8039216\n",
      "     0.81960785  0.8039216   0.84313726  0.84313726  0.78039217\n",
      "     0.70980394  0.69411767  0.69411767]\n",
      "   [ 0.75686276  0.79607844  0.8509804   0.8509804   0.7882353\n",
      "     0.69411767  0.7019608   0.8509804   0.90588236  0.6392157\n",
      "     0.03529418 -0.6        -0.7176471  -0.2235294   0.39607847\n",
      "     0.7490196   0.827451    0.75686276  0.81960785  0.9607843\n",
      "     0.92156863  0.8117647   0.77254903  0.7882353   0.8039216\n",
      "     0.8352941   0.84313726  0.85882354]\n",
      "   [ 0.7254902   0.73333335  0.7647059   0.8352941   0.8745098\n",
      "     0.77254903  0.7176471   0.9137255   0.75686276 -0.05098039\n",
      "    -0.78039217 -0.81960785 -0.24705881  0.5294118   0.9843137\n",
      "     0.9607843   0.85882354  0.7882353   0.54509807  0.39607847\n",
      "     0.6         0.7882353   0.6         0.4901961   0.73333335\n",
      "     0.92156863  0.8352941   0.7411765 ]\n",
      "   [ 0.92941177  0.8352941   0.69411767  0.70980394  0.8352941\n",
      "     0.84313726  0.8117647   0.8980392   0.64705884 -0.09803921\n",
      "    -0.79607844 -0.9607843  -0.42745095  0.4431373   0.8901961\n",
      "     0.75686276  0.7254902   0.8352941   0.654902    0.38823533\n",
      "     0.37254906  0.35686278  0.09019613 -0.02745098  0.2313726\n",
      "     0.6         0.7490196   0.77254903]\n",
      "   [ 0.7490196   0.77254903  0.8039216   0.79607844  0.7647059\n",
      "     0.7882353   0.84313726  0.8901961   0.75686276  0.4431373\n",
      "     0.14509809  0.05882359  0.2941177   0.6862745   0.88235295\n",
      "     0.79607844  0.69411767  0.7254902   0.8666667   0.94509804\n",
      "     0.7490196   0.49803925  0.47450984  0.4039216   0.11372554\n",
      "     0.0196079   0.21568632  0.37254906]\n",
      "   [ 0.8039216   0.79607844  0.79607844  0.79607844  0.8039216\n",
      "     0.7882353   0.78039217  0.77254903  0.8039216   0.8745098\n",
      "     0.94509804  0.96862745  0.90588236  0.8117647   0.79607844\n",
      "     0.85882354  0.8352941   0.75686276  0.7490196   0.81960785\n",
      "     0.8901961   0.94509804  0.9607843   0.88235295  0.7176471\n",
      "     0.5372549   0.45882356  0.4431373 ]\n",
      "   [ 0.7882353   0.7882353   0.7882353   0.7882353   0.7882353\n",
      "     0.78039217  0.7882353   0.7882353   0.7882353   0.77254903\n",
      "     0.75686276  0.75686276  0.7647059   0.78039217  0.78039217\n",
      "     0.77254903  0.78039217  0.79607844  0.7882353   0.75686276\n",
      "     0.7490196   0.7490196   0.75686276  0.7882353   0.8509804\n",
      "     0.8980392   0.92156863  0.92156863]\n",
      "   [ 0.7882353   0.7882353   0.7882353   0.7882353   0.7882353\n",
      "     0.79607844  0.79607844  0.79607844  0.7882353   0.7882353\n",
      "     0.7882353   0.7882353   0.7882353   0.7882353   0.7882353\n",
      "     0.78039217  0.8117647   0.8509804   0.81960785  0.7490196\n",
      "     0.7647059   0.78039217  0.7254902   0.7254902   0.8352941\n",
      "     0.8980392   0.84313726  0.7882353 ]\n",
      "   [ 0.8352941   0.8352941   0.8352941   0.8352941   0.827451\n",
      "     0.827451    0.827451    0.827451    0.827451    0.8352941\n",
      "     0.8352941   0.8352941   0.8352941   0.8352941   0.8352941\n",
      "     0.827451    0.8666667   0.8901961   0.8666667   0.8352941\n",
      "     0.8901961   0.92941177  0.8666667   0.81960785  0.8666667\n",
      "     0.88235295  0.827451    0.77254903]\n",
      "   [-0.85882354 -0.85882354 -0.85882354 -0.85882354 -0.85882354\n",
      "    -0.85882354 -0.85882354 -0.85882354 -0.85882354 -0.85882354\n",
      "    -0.85882354 -0.85882354 -0.85882354 -0.85882354 -0.8666667\n",
      "    -0.88235295 -0.8901961  -0.8901961  -0.8980392  -0.8901961\n",
      "    -0.8509804  -0.827451   -0.8509804  -0.8901961  -0.8980392\n",
      "    -0.8901961  -0.88235295 -0.88235295]]]]\n"
     ]
    }
   ],
   "source": [
    "# 加载数据并开始预测\n",
    "with fluid.scope_guard(inference_scope):\n",
    "    #获取训练好的模型\n",
    "    #从指定目录中加载 推理model(inference model)\n",
    "    [inference_program,                                           #推理Program\n",
    "     feed_target_names,                                           #是一个str列表，它包含需要在推理 Program 中提供数据的变量的名称。 \n",
    "     fetch_targets] = fluid.io.load_inference_model(model_save_dir,#fetch_targets：是一个 Variable 列表，从中我们可以得到推断结果。model_save_dir：模型保存的路径\n",
    "                                                    infer_exe)     #infer_exe: 运行 inference model的 executor\n",
    "    img = load_image('../../CheckCode/data/6.jpg')\n",
    "\n",
    "    results = exe.run(program=inference_program,     #运行推测程序\n",
    "                   feed={feed_target_names[0]: img}, #喂入要预测的img\n",
    "                   fetch_list=fetch_targets)         #得到推测结果,    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿到每个标签的概率值之后，我们要获取概率最大的标签，并打印出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该图片的预测结果的label为: 5\n"
     ]
    }
   ],
   "source": [
    "# 获取概率最大的label\n",
    "lab = np.argsort(results)                               #argsort函数返回的是result数组值从小到大的索引值\n",
    "#print(lab)\n",
    "print(\"该图片的预测结果的label为: %d\" % lab[0][0][-1])  #-1代表读取数组中倒数第一列  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：训练和预测的图像来源不同，造成预测错误。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
